{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minor-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from socket import gethostname\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import constants\n",
    "\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "HBARC = constants.physical_constants[\"natural unit of action in eV s\"][0] * constants.c * 1.e09 # in MeV fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "european-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpwdata.densities.models import Density2N, Density1N\n",
    "from numpwdata.densities.models import Chiral as ChiralInteraction\n",
    "from numpwdata.files.models import H5File, DatFile\n",
    "from numpwd.densities import Density, read_h5, read_1N_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "settled-owner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jureca\n",
      "/p/project/cjikp03/koerber1/src/nuc/project-dm/\n",
      "project-dm-db.sqlite3 \n"
     ]
    }
   ],
   "source": [
    "from espressodb.management.utilities.version import get_db_info\n",
    "HOSTNAME = gethostname().split(\".\")[-1]\n",
    "print(HOSTNAME)\n",
    "print(os.environ[\"NUMPWDATA_CONFIG_DIR\"])\n",
    "db_name, db_user = get_db_info()\n",
    "print(db_name, db_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "molecular-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSDIR = os.path.join(os.getcwd(), \"densities-new\")\n",
    "DENSITIES = os.listdir(DENSDIR)\n",
    "\n",
    "H5_DENSITIES = [d for d in DENSITIES if d.endswith(\".h5\")]\n",
    "DAT_DENSITIES = [d for d in DENSITIES if d.endswith(\".dat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "novel-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS = (\n",
    "    r\"compton-dens-(?P<nuc>[0-9A-z]+)\",\n",
    "    r\"\\-(?P<potential>[a-z0-9\\+]+)\",\n",
    "    r\"\\-(?P<order>[a-z0-9\\+]+)\",\n",
    "    r\"\\-cut=(?P<cut>[0-9]+)\",\n",
    "    r\"\\-(?P<empot>[a-zA-Z]+)\",\n",
    "    r\"\\-(?P<cmpi>(?:[a-z0-9]+))\",\n",
    "    r\"(\\-(?P<combine>combine))?\",\n",
    "    r\"(\\-Lam=(?P<Lam>(?:[\\.0-9]+)))?\",\n",
    "    r\"(\\-c1=(?P<c1>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-c3=(?P<c3>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-c4=(?P<c4>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-cd=(?P<cd>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-ce=(?P<ce>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-cE1=(?P<cE1>(?:[\\-\\.0-9]+)))?\",\n",
    "    r\"(\\-Lambdanumeric=(?P<lambda>(?:[0-9\\.e\\+]+)))?\",\n",
    "    r\"(\\-tnfcut=(?P<tnfcut>(?:[0-9]+)))?\",\n",
    "    r\"\\-om=(?P<omega>(?:[0-9\\.]+E[\\+\\-][0-9]+))\",\n",
    "    r\"\\-th=(?P<theta>(?:[0-9\\.E\\+]+))\",\n",
    "    r\"(\\-nx=(?P<nx>(?:[0-9]+)))?\",\n",
    "    r\"(\\-nphi=(?P<nphi>(?:[0-9]+)))?\",\n",
    "    r\"(\\-np12\\=np34\\=(?P<np12_np34>(?:[0-9\\+]+)))?\",\n",
    "    r\"(\\-np3\\=(?P<np3>(?:[0-9\\+]+)))?\",\n",
    "    r\"(\\-nq4\\=nq=(?P<nq4_nq>(?:[0-9\\+]+)))?\",\n",
    "    r\"\\-j12max=(?P<j12max>(?:[0-9]+))\",\n",
    "    r\"\\-lmax=(?P<lmax>(?:[0-9]+))\",\n",
    "    r\"\\-lsummax=(?P<lsummax>(?:[0-9]+))\",\n",
    "    r\"\\-tau4max=(?P<tau4max>(?:[0-9]+))\",\n",
    "    r\"\\-rho(1b)?\",\n",
    ")\n",
    "DTYPES = {\n",
    "    int: [\"j12max\", \"lmax\", \"lsummax\", \"tau4max\", \"cut\"],\n",
    "    float: [\"lambda\", \"omega\", \"theta\", \"c1\", \"c3\", \"c4\", \"ce\", \"cd\", \"cE1\", \"Lam\"],\n",
    "}\n",
    "PATTERN = re.compile(\"\".join(PATTERNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "printable-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging h5 density pattern\n",
      "compton-dens-4he-chsms-nlo-cut=3-pCoul-no3nf-om=1.20E+00-th=1.80E+02-j12max=5-lmax=6-lsummax=10-tau4max=0-rho.h5\n",
      "No issues\n",
      "Debugging dat density pattern\n",
      "compton-dens-4he-chsms-n4lo+-cut=3-pCoul-n2lo-combine-Lam=500.000-c1=-1.230-c3=-4.650-c4=3.280-cd=1.00-ce=-0.88-cE1=-1.00-om=3.70E+02-th=1.80E+02-j12max=5-lmax=6-lsummax=10-tau4max=0-rho1b.dat\n",
      "No issues\n"
     ]
    }
   ],
   "source": [
    "print(\"Debugging h5 density pattern\")\n",
    "dens = H5_DENSITIES[0]\n",
    "extension = \"h5\"\n",
    "print(dens)\n",
    "\n",
    "for n, pat in enumerate(PATTERNS):\n",
    "    pattern = re.compile(\"\".join(PATTERNS[:n]))\n",
    "    if pattern.search(dens) is None:\n",
    "        print(\"\".join(PATTERNS[:n]))\n",
    "        raise KeyError\n",
    "print(\"No issues\")\n",
    "\n",
    "print(\"Debugging dat density pattern\")\n",
    "dens = DAT_DENSITIES[0]\n",
    "extension = \"dat\"\n",
    "print(dens)\n",
    "\n",
    "for n, pat in enumerate(PATTERNS):\n",
    "    pattern = re.compile(\"\".join(PATTERNS[:n]))\n",
    "    if pattern.search(dens) is None:\n",
    "        print(\"\".join(PATTERNS[:n]))\n",
    "        raise KeyError\n",
    "print(\"No issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "adequate-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_names(directory, extension):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(f\".{extension}\")]\n",
    "    \n",
    "    pattern = re.compile(\"\".join(PATTERNS))\n",
    "    densities = pd.DataFrame([pattern.search(el).groupdict() for el in files])\n",
    "    for dtype, cols in DTYPES.items():\n",
    "        for col in cols:\n",
    "            densities[col] = densities[col].astype(dtype)\n",
    "\n",
    "    densities[\"qval\"] = densities[\"omega\"] / HBARC * 2\n",
    "    densities[\"file\"] = [os.path.join(DENSDIR, f) for f in files]\n",
    "    densities[\"owner\"] = \"Nogga\"\n",
    "    return (\n",
    "        densities.sort_values(\"omega\").reset_index(drop=True)\n",
    "        if not densities.empty\n",
    "        else densities\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "hollow-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_df = parse_file_names(DENSDIR, \"h5\")\n",
    "dat_df = parse_file_names(DENSDIR, \"dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-filter",
   "metadata": {},
   "source": [
    "Identify columns with not present entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "understood-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nuc          False\n",
       "potential    False\n",
       "order        False\n",
       "cut          False\n",
       "empot        False\n",
       "cmpi         False\n",
       "combine       True\n",
       "Lam           True\n",
       "c1            True\n",
       "c3            True\n",
       "c4            True\n",
       "cd            True\n",
       "ce            True\n",
       "cE1           True\n",
       "lambda        True\n",
       "tnfcut        True\n",
       "omega        False\n",
       "theta        False\n",
       "nx            True\n",
       "nphi          True\n",
       "np12_np34     True\n",
       "np3           True\n",
       "nq4_nq        True\n",
       "j12max       False\n",
       "lmax         False\n",
       "lsummax      False\n",
       "tau4max      False\n",
       "qval         False\n",
       "file         False\n",
       "owner        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_df.isna().any() | dat_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "atmospheric-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 400.0, 2: 450.0, 3: 500.0, 4: 550.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_map = dat_df.groupby(\"cut\")[\"Lam\"].mean().to_dict()\n",
    "cutoff_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-image",
   "metadata": {},
   "source": [
    "apparently, the N4LO+ interactions are only uniqely qunatified when also including cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "defensive-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not filtering with cd\n",
      "['n4lo+']\n",
      "filtering with cd\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "counts_dat = dat_df.groupby([\"potential\", \"order\", \"cut\", \"empot\", \"qval\"])[\"file\"].count()\n",
    "counts_h5 = h5_df.groupby([\"potential\", \"order\", \"cut\", \"empot\", \"qval\"])[\"file\"].count()\n",
    "\n",
    "print(\"not filtering with cd\")\n",
    "print(counts_dat[counts_dat > 1].append(counts_h5[counts_h5 > 1]).reset_index()[\"order\"].unique())\n",
    "\n",
    "counts_dat = dat_df.groupby([\"potential\", \"order\", \"cut\", \"empot\", \"qval\", \"cd\"])[\"file\"].count()\n",
    "counts_h5 = h5_df.groupby([\"potential\", \"order\", \"cut\", \"empot\", \"qval\", \"cd\"])[\"file\"].count()\n",
    "\n",
    "print(\"filtering with cd\")\n",
    "print(counts_dat[counts_dat > 1].append(counts_h5[counts_h5 > 1]).reset_index()[\"order\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cheap-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'chsms-N4LO+-cd=0.65',\n",
       "  'order': 'N4LO+',\n",
       "  'regulator': '400.0',\n",
       "  'em_potential': True,\n",
       "  'tag': 'cd=0.65'},\n",
       " {'publication': None,\n",
       "  'misc': {'empot': 'pCoul',\n",
       "   'cut': 1,\n",
       "   'cmpi': 'n2lo',\n",
       "   'combine': 'combine',\n",
       "   'c1': -1.23,\n",
       "   'c3': -4.65,\n",
       "   'c4': 3.28,\n",
       "   'ce': 0.13,\n",
       "   'cE1': 1.0,\n",
       "   'cd': 0.65}})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_interaction_kwargs(info):\n",
    "    tag = \"cd={cd:0.2f}\".format(cd=info[\"cd\"])\n",
    "    name = info[\"potential\"]\n",
    "    order = info[\"order\"].upper()\n",
    "    if order == \"N4LO+\":\n",
    "        name += \"-\" + order + \"-\" + tag\n",
    "    interaction_id_kwargs = dict(\n",
    "        name=name,\n",
    "        order=order,\n",
    "        regulator=str(cutoff_map[info[\"cut\"]]),\n",
    "        em_potential=info[\"empot\"] == \"pCoul\",\n",
    "        tag=tag # Adding tags to make interactions unique\n",
    "    )\n",
    "    misc = {key: info.get(key) \n",
    "        for key in [\"empot\", \"cut\", \"cmpi\", \"combine\", \"c1\", \"c3\", \"c4\", \"ce\", \"cE1\", \"cd\"]\n",
    "    }\n",
    "    misc = {key: None if (isinstance(val, float) and np.isnan(val)) else val for key, val in misc.items()}\n",
    "    interaction_update_kwargs = dict(\n",
    "        publication=None,  # needs update\n",
    "        misc=misc,\n",
    "    )\n",
    "    return interaction_id_kwargs, interaction_update_kwargs\n",
    "\n",
    "def update_or_create_interaction(interaction_id_kwargs, interaction_update_kwargs, verbose=False):\n",
    "    interaction, created = ChiralInteraction.objects.get_or_create(\n",
    "        **interaction_id_kwargs\n",
    "    )\n",
    "    if created and verbose:\n",
    "        print(\"created DB entry for\", interaction)\n",
    "    for key, val in interaction_update_kwargs.items():\n",
    "        setattr(interaction, key, val)\n",
    "    interaction.save()\n",
    "    return interaction, created\n",
    "\n",
    "map_interaction_kwargs(dat_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eligible-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_density_kwargs(interaction, file, info):\n",
    "    assert info[\"nuc\"] == \"4he\"\n",
    "    density_id_kwargs = dict(\n",
    "        nucleus=info[\"nuc\"],\n",
    "        n_nuc=4,\n",
    "        interaction=interaction,\n",
    "        qval=\"{0:8.5f}\".format(info[\"qval\"]),\n",
    "        thetaval=\"{0:5.2f}\".format(info[\"theta\"]),\n",
    "        file=file,\n",
    "    )\n",
    "    if isinstance(file, H5File):\n",
    "        dens = read_h5(file.path)\n",
    "        momentum_info={**dens.mesh_info, **dens.current_info}\n",
    "    elif isinstance(file, DatFile):\n",
    "        dens = read_1N_density(file.path)\n",
    "        momentum_info={key: dens[\"om_theta\"][n] for n, key in enumerate([\"omega\", \"thetaval\", \"qval\", \"thetaqval\"])}\n",
    "    else:\n",
    "        raise TypeError(file)\n",
    "\n",
    "    density_update_kwargs = dict(\n",
    "        momentum_info=momentum_info,\n",
    "        channel_info={\n",
    "            key: info.get(key) for key in [\"j12max\", \"lmax\", \"lsummax\", \"tau4max\"]\n",
    "        },\n",
    "        mesh_info={\n",
    "            key: info.get(key) for key in [\"nx\", \"nphi\", \"np3\", \"nq4_nq\", \"np12_np34\"]\n",
    "        },\n",
    "    )\n",
    "    return density_id_kwargs, density_update_kwargs\n",
    "\n",
    "# file = H5File.objects.first()\n",
    "#interaction = ChiralInteraction.objects.first()\n",
    "\n",
    "#map_density_kwargs(interaction, file, dat_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "certified-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_or_create_density(info, density_kind=Density2N, verbose=False):\n",
    "    interaction_id_kwargs, interaction_update_kwargs = map_interaction_kwargs(info)\n",
    "    try:\n",
    "        interaction, created = update_or_create_interaction(interaction_id_kwargs, interaction_update_kwargs, verbose=verbose)\n",
    "    except Exception as e:\n",
    "        print(\"update_or_create_interaction failed for:\")\n",
    "        print(interaction_id_kwargs)\n",
    "        print(interaction_update_kwargs)\n",
    "        raise(e)\n",
    "\n",
    "    file_kwargs = {\"path\": info[\"file\"], \"hostname\": HOSTNAME}\n",
    "    if info[\"file\"].endswith(\".h5\"):\n",
    "        FileClass = H5File\n",
    "    elif info[\"file\"].endswith(\".dat\"):\n",
    "        FileClass = DatFile\n",
    "    else:\n",
    "        raise TypeError(\"Do no know how to parse: \" + info[\"file\"])\n",
    "    file, created = FileClass.objects.get_or_create(**file_kwargs)\n",
    "    if created and verbose:\n",
    "        print(\"created DB entry for\", file)\n",
    "\n",
    "    density_id_kwargs, density_update_kwargs = map_density_kwargs(interaction, file, info)\n",
    "\n",
    "    if (density_kind is Density2N and not isinstance(file, H5File)) or (density_kind is Density1N and not isinstance(file, DatFile)):\n",
    "        raise TypeError(f\"Unexpected combination for file and denisty kind: {file}, {density_kind}\")\n",
    "\n",
    "    density, created = density_kind.objects.get_or_create(**density_id_kwargs)\n",
    "    if created and verbose:\n",
    "        print(\"created DB entry for\", density)\n",
    "\n",
    "    for key, val in density_update_kwargs.items():\n",
    "        setattr(density, key, val)\n",
    "    density.save()\n",
    "\n",
    "    return density, created"
   ]
  },
  {
   "cell_type": "raw",
   "id": "sitting-shakespeare",
   "metadata": {},
   "source": [
    "info = dat_df.iloc[0]\n",
    "update_or_create_density(info, density_kind=Density1N, verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "harmful-dubai",
   "metadata": {},
   "source": [
    "info = h5_df.iloc[0]\n",
    "update_or_create_density(info, density_kind=Density2N, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aggressive-annual",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [02:26<00:00, 13.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, info in tqdm(list(dat_df.iterrows())):\n",
    "    update_or_create_density(info, density_kind=Density1N, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "considerable-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [37:14<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, info in tqdm(list(h5_df.iterrows())):\n",
    "    update_or_create_density(info, density_kind=Density2N, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-teens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-dm",
   "language": "python",
   "name": "project-dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
